{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#JupyterHub\" data-toc-modified-id=\"JupyterHub-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>JupyterHub</a></div><div class=\"lev2 toc-item\"><a href=\"#Installing-Jupyter-Notebook\" data-toc-modified-id=\"Installing-Jupyter-Notebook-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Installing Jupyter Notebook</a></div><div class=\"lev3 toc-item\"><a href=\"#Install-Anaconda-for-Python3\" data-toc-modified-id=\"Install-Anaconda-for-Python3-111\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Install Anaconda for Python3</a></div><div class=\"lev3 toc-item\"><a href=\"#Install-Anaconda\" data-toc-modified-id=\"Install-Anaconda-112\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Install Anaconda</a></div><div class=\"lev2 toc-item\"><a href=\"#Configure-Jupyter-Notebook\" data-toc-modified-id=\"Configure-Jupyter-Notebook-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Configure Jupyter Notebook</a></div><div class=\"lev2 toc-item\"><a href=\"#Test-the-notebook-server\" data-toc-modified-id=\"Test-the-notebook-server-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Test the notebook server</a></div><div class=\"lev2 toc-item\"><a href=\"#Adding-the-kernels-to-the-notebook-server\" data-toc-modified-id=\"Adding-the-kernels-to-the-notebook-server-14\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Adding the kernels to the notebook server</a></div><div class=\"lev3 toc-item\"><a href=\"#Add-PySpark-kernel\" data-toc-modified-id=\"Add-PySpark-kernel-141\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Add PySpark kernel</a></div><div class=\"lev4 toc-item\"><a href=\"#Check-Python-version\" data-toc-modified-id=\"Check-Python-version-1411\"><span class=\"toc-item-num\">1.4.1.1&nbsp;&nbsp;</span>Check Python version</a></div><div class=\"lev4 toc-item\"><a href=\"#Install-IPython-for-Python2\" data-toc-modified-id=\"Install-IPython-for-Python2-1412\"><span class=\"toc-item-num\">1.4.1.2&nbsp;&nbsp;</span>Install IPython for Python2</a></div><div class=\"lev4 toc-item\"><a href=\"#Testing-the-PySpark-kernel\" data-toc-modified-id=\"Testing-the-PySpark-kernel-1413\"><span class=\"toc-item-num\">1.4.1.3&nbsp;&nbsp;</span>Testing the PySpark kernel</a></div><div class=\"lev4 toc-item\"><a href=\"#Errors-in-notebook-server\" data-toc-modified-id=\"Errors-in-notebook-server-1414\"><span class=\"toc-item-num\">1.4.1.4&nbsp;&nbsp;</span>Errors in notebook server</a></div><div class=\"lev3 toc-item\"><a href=\"#Add-the-R-kernel-(compile)\" data-toc-modified-id=\"Add-the-R-kernel-(compile)-142\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Add the R kernel (compile)</a></div><div class=\"lev4 toc-item\"><a href=\"#Testing-R\" data-toc-modified-id=\"Testing-R-1421\"><span class=\"toc-item-num\">1.4.2.1&nbsp;&nbsp;</span>Testing R</a></div><div class=\"lev4 toc-item\"><a href=\"#Test-SparkR\" data-toc-modified-id=\"Test-SparkR-1422\"><span class=\"toc-item-num\">1.4.2.2&nbsp;&nbsp;</span>Test SparkR</a></div><div class=\"lev3 toc-item\"><a href=\"#Add-the-Spark-Scala-kernel-(through-Apache-Toree)\" data-toc-modified-id=\"Add-the-Spark-Scala-kernel-(through-Apache-Toree)-143\"><span class=\"toc-item-num\">1.4.3&nbsp;&nbsp;</span>Add the Spark-Scala kernel (through Apache Toree)</a></div><div class=\"lev4 toc-item\"><a href=\"#Test-Spark-Scala\" data-toc-modified-id=\"Test-Spark-Scala-1431\"><span class=\"toc-item-num\">1.4.3.1&nbsp;&nbsp;</span>Test Spark-Scala</a></div><div class=\"lev2 toc-item\"><a href=\"#Installing-JupyterHub\" data-toc-modified-id=\"Installing-JupyterHub-15\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Installing JupyterHub</a></div><div class=\"lev3 toc-item\"><a href=\"#Install-NodeJS-and-its-package-manager\" data-toc-modified-id=\"Install-NodeJS-and-its-package-manager-151\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>Install NodeJS and its package manager</a></div><div class=\"lev3 toc-item\"><a href=\"#Install-JupyterHub\" data-toc-modified-id=\"Install-JupyterHub-152\"><span class=\"toc-item-num\">1.5.2&nbsp;&nbsp;</span>Install JupyterHub</a></div><div class=\"lev3 toc-item\"><a href=\"#Configure-JupyterHub\" data-toc-modified-id=\"Configure-JupyterHub-153\"><span class=\"toc-item-num\">1.5.3&nbsp;&nbsp;</span>Configure JupyterHub</a></div><div class=\"lev3 toc-item\"><a href=\"#Test-JupyterHub\" data-toc-modified-id=\"Test-JupyterHub-154\"><span class=\"toc-item-num\">1.5.4&nbsp;&nbsp;</span>Test JupyterHub</a></div><div class=\"lev3 toc-item\"><a href=\"#Locking-down-the-environment\" data-toc-modified-id=\"Locking-down-the-environment-155\"><span class=\"toc-item-num\">1.5.5&nbsp;&nbsp;</span>Locking down the environment</a></div><div class=\"lev4 toc-item\"><a href=\"#Running-JupyterHub-without-root\" data-toc-modified-id=\"Running-JupyterHub-without-root-1551\"><span class=\"toc-item-num\">1.5.5.1&nbsp;&nbsp;</span>Running JupyterHub without root</a></div><div class=\"lev4 toc-item\"><a href=\"#Setting-up-SSL-encryption\" data-toc-modified-id=\"Setting-up-SSL-encryption-1552\"><span class=\"toc-item-num\">1.5.5.2&nbsp;&nbsp;</span>Setting up SSL encryption</a></div><div class=\"lev4 toc-item\"><a href=\"#Create-a-whitelist-of-allowed-users\" data-toc-modified-id=\"Create-a-whitelist-of-allowed-users-1553\"><span class=\"toc-item-num\">1.5.5.3&nbsp;&nbsp;</span>Create a whitelist of allowed users</a></div><div class=\"lev4 toc-item\"><a href=\"#Create-directories-to-keep-the-notebooks\" data-toc-modified-id=\"Create-directories-to-keep-the-notebooks-1554\"><span class=\"toc-item-num\">1.5.5.4&nbsp;&nbsp;</span>Create directories to keep the notebooks</a></div><div class=\"lev2 toc-item\"><a href=\"#JupyterHub-as-system-service\" data-toc-modified-id=\"JupyterHub-as-system-service-16\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>JupyterHub as system service</a></div><div class=\"lev2 toc-item\"><a href=\"#Make-jupyterhub-admin-users\" data-toc-modified-id=\"Make-jupyterhub-admin-users-17\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Make jupyterhub admin users</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JupyterHub\n",
    "Multi-Tenant notebook implementation\n",
    "Implementation steps\n",
    "Version 6, 2016-11-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we set the name of the server to install on. We also define the an alias 'remote' to ease writing commands ot the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export SERVER=kac-srv-001.kac.sblokalnet\n",
    "export LUSER=abr-sadm\n",
    "alias remote=\"ssh -t $LUSER@$SERVER export PATH=/opt/anaconda3/bin:\\$PATH \\&\\& \"\n",
    "alias remotesudo=\"remote cd /tmp \\&\\& sudo env PATH=/opt/anaconda3/bin:\\$PATH \"\n",
    "alias start_notebook='remote \\(yes \\| jupyter notebook --ip=\\$\\(hostname -f \\)\\)'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Jupyter Notebook\n",
    "\n",
    "\n",
    "First we will install and test the Jupyter notebook as this is the basis for the user interface presented to the analysts. Both Jupyter and JupyterHub are best installed through Anaconda, a Python distribution that includes most libraries needed by people tasked with the analysis of data.\n",
    "\n",
    "### Install Anaconda for Python3\n",
    "\n",
    "IBM Open Platform is based on Python2. JupyterHub however requires Python3, so we must first start with Anaconda for Python3.\n",
    "Download Anaconda\n",
    "Download Anaconda 4.x for Python3 from: https://www.continuum.io/downloads \n",
    "\n",
    "Once downloaded, upload the shell script (Anaconda3….sh) to the BigInsights node that runs the Spark driver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Anaconda\n",
    "Run the following commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remote rm -rf /tmp/Anaconda3-4.2.0-Linux-x86_64.sh\n",
    "remote wget https://repo.continuum.io/archive/Anaconda3-4.2.0-Linux-x86_64.sh -O /tmp/Anaconda3-4.2.0-Linux-x86_64.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now start the installation; this can take a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remote chmod a+x /tmp/Anaconda3-4.2.0-Linux-x86_64.sh\n",
    "remotesudo bash /tmp/Anaconda3-4.2.0-Linux-x86_64.sh -b -p /opt/anaconda3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The installation now starts; this can take a couple of minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Jupyter Notebook\n",
    "As we’re planning to use a single configuration across notebook users, the notebook configuration will be created at a central location, /etc/jupyter.\n",
    "Execute the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remotesudo mkdir -p /etc/jupyter\n",
    "remotesudo jupyter notebook -y --generate-config --config=/etc/jupyter/jupyter_notebook_config.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the configuration so that Jupyter will not try and start a browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remotesudo \"sed -i 's/^[#]\\?c\\.NotebookApp\\.open_browser.*/c.NotebookApp.open_browser=False'/ /etc/jupyter/jupyter_notebook_config.py\"\n",
    "remote grep open_browser /etc/jupyter/jupyter_notebook_config.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the parameter \"c.NotebookApp.open_browser\" to \"False\" and save the configuration file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the notebook server\n",
    "Now that the Jupyter notebook is configured, run a basic test against it by starting it and opening a notebook. For basic Python testing, you can start the notebook server as user root, but with Spark notebooks you will need access to the HDFS directory structure.\n",
    "\n",
    "Start the notebook server as your normal user by entering the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some information and warning messages will be issued. You can ignore the warning messages; they do not hinder the running of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, start a browser and navigate to the Jupyter notebook using address:\n",
    "http://jupyter-system-ip-address:8888 \n",
    "Create a new Python notebook and enter a Python statement, for example “print(1+1)”. Then execute it using Shift-Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](jupyterInitial.png \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you’ve tested that the notebook server works, shut it down by interrupting the above command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the kernels to the notebook server\n",
    "By default, only a Python3 kernel is available from the notebook server. In this section we will add the PySpark, Scala and R kernels to the notebook configuration so they can be used by the analysts.\n",
    "Even though it is possible to configure kernels per user, we define the kernels in a central location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add PySpark kernel\n",
    "Before adding the PySpark kernel to the Jupyter notebook, we first need to ensure that the ipykernel is available for Python2, as this is the basis for Spark 1.x.y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Python version\n",
    "Please ensure that the python command executes Python 2.7. You may have to remove /opt/anaconda3/bin from the path and/or add the /opt/anaconda2/bin at the beginning of the path.\n",
    "Run the following command to determine the Python version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remote python2 -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result should be like the following:\n",
    "\n",
    "    Python 2.7.12 :: Anaconda 4.2.0 (64-bit)\n",
    "or\n",
    "\n",
    "    Python 2.7.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, record the location of the command. You will need this later when you specify the path in the kernel.json files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remote which -a python2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the python command was found in /bin. Another location could be /usr/bin or /opt/anaconda2/bin (if you have installed it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Install IPython for Python2\n",
    "Dependent on whether you have installed Anaconda2 or you’re using a pre-installed Python2 package, you may have to install pip and the IPython kernel. Run the following commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remotesudo yum install -y python-pip\n",
    "remotesudo pip install ipykernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can ignore the warning messages if pip and the IPython kernel are already installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following commands to add the PySpark kernel to the notebook configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remotesudo mkdir -p /usr/share/jupyter/kernels/pyspark\n",
    "remotesudo touch /usr/share/jupyter/kernels/pyspark/kernel.json\n",
    "python << EOJ | remotesudo tee /usr/share/jupyter/kernels/pyspark/kernel.json\n",
    "print(\"\"\"\n",
    "{\n",
    "    \"display_name\": \"PySpark\",\n",
    "    \"language\": \"python\",\n",
    "    \"argv\": [ \"/usr/bin/python2\", \"-m\", \"ipykernel\", \"-f\", \"{connection_file}\" ],\n",
    "    \"env\": {\n",
    "        \"PATH\": \"/bin:/sbin:/usr/sbin:/usr/bin:/usr/ibmpacks/current/bigsql/bigsql/bin\",\n",
    "        \"SPARK_HOME\": \"/usr/iop/current/spark-client\",\n",
    "        \"PYSPARK_PYTHON\": \"/usr/bin/python2\",\n",
    "        \"PYTHONPATH\": \"/usr/iop/current/spark-client/python/:/usr/iop/current/spark-client/python/lib/py4j-0.9-src.zip\",\n",
    "        \"PYTHONSTARTUP\": \"/usr/iop/current/spark-client/python/pyspark/shell.py\",\n",
    "        \"PYSPARK_SUBMIT_ARGS\": \"--master yarn-client pyspark-shell\"\n",
    "    }\n",
    "}\"\"\")\n",
    "EOJ\n",
    "#remote cat /usr/share/jupyter/kernels/pyspark/kernel.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a close look at the various properties to ensure they match your environment.\n",
    "* \"argv\": \"/bin/python\" The full path of the python command as determined in the previous section\n",
    "* \"PATH\": \"/bin: …\" Ensure that the directory holding the python command is first in the path\n",
    "* \"PYSPARK_PYTHON\": \"/bin/python\" The full path of the python command as determined in the previous section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\tMake sure you don’t copy any special characters such as tabs or formatting into the JSON file, otherwise it will fail to be parsed.\n",
    "\n",
    "**Path:**\tThe PATH is explicitly set in the kernel.json file to ensure that the PySpark shell scripts are executed using Python2, instead of Python3. Failing to do so results in syntax errors in the notebook server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once finished, check that the kernel is now available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remote jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should render the following output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Available kernels:\n",
    "      python3    /opt/anaconda3/lib/python3.5/site-packages/ipykernel/resources\n",
    "      pyspark    /usr/share/jupyter/kernels/pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the PySpark kernel\n",
    "Once the PySpark kernel has been added, start the notebook server using user spark by entering the following commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test a basic expression such as “print(sc.version)”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](jupyterSpark.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another test you can do is to write a file into Hadoop and subsequently read it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    l=range(1000000)\n",
    "    rdd=sc.parallelize(l).map(lambda x:x+1)\n",
    "    rdd.saveAsTextFile('/tmp/output.txt')\n",
    "    readFile=sc.textFile('/tmp/output.txt')\n",
    "    readFile.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should return a value of 1000000.\n",
    "\n",
    "Once finished, save or discard the notebook and close the notebook using File -> Close and Halt. This will also stop the PySpark session.\n",
    "\n",
    "In the terminal that is running the notebook server, you will see a lot of messages when Spark is started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Errors in notebook server\n",
    "##### Endless messages in notebook server\n",
    "If you start PySpark or any other notebook that is dependent on Spark and you see endless messages in the notebook server:\n",
    "\n",
    "    16/10/15 02:27:38 INFO Client: Application report for application_1476515684661_0002 (state: ACCEPTED)\n",
    "    16/10/15 02:27:39 INFO Client: Application report for application_1476515684661_0002 (state: ACCEPTED)\n",
    "    16/10/15 02:27:40 INFO Client: Application report for application_1476515684661_0002 (state: ACCEPTED)\n",
    "This typically means that YARN was not started or not properly running. Check your Ambari console to ensure YARN and its node managers are up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Errors in the notebook server – Cannot connect to port 8050\n",
    "If errors such as the following appear in the terminal where you have started the Jupyter notebook server, Spark or Hive is probably not started.\n",
    "\n",
    "    16/10/14 04:43:24 INFO Client: Retrying connect to server: biginsights-sn.demos.demoibm.com/10.137.41.71:8050. Already tried 22 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=50, sleepTime=1000 MILLISECONDS) \n",
    "In that case you should check the Ambari console to see that the services are running. Also you can test that PySpark is working properly by running the following command as the Spark user and check that you can enter PySpark commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Python errors in Jupyter console – missing parentheses\n",
    "If PySpark (or one of the other Spark-related kernels) is started with Python3, you will see errors in the notebook server, even though the notebook itself may seem to work properly.\n",
    "\n",
    "    16/10/04 12:17:13 WARN ScriptBasedMapping: Exception running /etc/hadoop/conf/topology_script.py 172.16.7.130 \n",
    "    ExitCodeException exitCode=1:   File \"/etc/hadoop/conf/topology_script.py\", line 63\n",
    "        print rack\n",
    "                 ^\n",
    "    SyntaxError: Missing parentheses in call to 'print'\n",
    "In the example PySpark kernel.json, we are explicitly setting the PATH environment variable to ensure /bin/python is at the beginning of the path. Make sure that /bin/python starts Python2.\n",
    "\n",
    "    [spark@biginsights-sn ~]$ /bin/python\n",
    "    Python 2.7.5 (default, Oct 11 2015, 17:47:16) \n",
    "    [GCC 4.8.3 20140911 (Red Hat 4.8.3-9)] on linux2\n",
    "    Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
    "    >>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Add the R kernel (compile)\n",
    "As the R kernel is not part of the CRAN repos it should be compiled from sources. Start by getting the following additional packages (if they are not already part of your OS installation). Run the following commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remotesudo yum install -y R\n",
    "remotesudo yum install -y openssl-devel openssl libcurl-devel libssh2-devel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create links to libssl.so.1.0.0 and libcrypto.so.1.0.0 under /usr/lib64 to avoid errors like \"libssl.so.10: cannot open shared object file\" during compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remotesudo ln -s /opt/anaconda3/lib/libssl.so.1.0.0 /usr/lib64/libssl.so.1.0.0\n",
    "remotesudo ln -s /opt/anaconda3/lib/libcrypto.so.1.0.0 /usr/lib64/libcrypto.so.1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start R using root and install the git2r, devtools, repr, IRdisplay, crayon and pbdZMQ packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remote sudo -i R --vanilla << EOR\n",
    "install.packages(c('git2r','devtools','repr','IRdisplay','crayon','pbdZMQ'),repos=\"http://cran.rstudio.com/\")\n",
    "EOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once complete you can use the devtools package to get and compile IRkernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remote sudo -i R --vanilla << EOR\n",
    "devtools::install_github('IRkernel/IRkernel')\n",
    "EOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are planning to use SparkR now it's the time to get and install the SparkR package (make sure to use the correct package version for your version of Spark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remote sudo -i R --vanilla << EOR\n",
    "devtools::install_github('apache/spark@v1.6.1', subdir='R/pkg')\n",
    "EOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create the kernel specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remote sudo mkdir -p /usr/share/jupyter/kernels/r\n",
    "python << EOJ | remotesudo tee  /usr/share/jupyter/kernels/r/kernel.json\n",
    "print(\"\"\"\n",
    "{\n",
    " \"argv\": [\"R\", \"--slave\", \"-e\", \"IRkernel::main()\", \"--args\", \"{connection_file}\"],\n",
    " \"display_name\":\"R and SparkR\",\n",
    " \"language\":\"R\",\n",
    " \"env\": {\n",
    "    \"PATH\": \"/bin:/usr/ibmpacks/current/bigsql/bigsql/bin:/sbin:/usr/sbin:/usr/bin:/opt/anaconda3/bin\"\n",
    " }\n",
    "}\"\"\")\n",
    "EOJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remote jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result should look something like this:\n",
    "\n",
    "    Available kernels:\n",
    "      python3    /opt/anaconda3/lib/python3.5/site-packages/ipykernel/resources\n",
    "      pyspark    /usr/share/jupyter/kernels/pyspark\n",
    "      r          /usr/share/jupyter/kernels/r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start (restart) your notebook server and verify that the new kernels are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing R\n",
    "First test that R is working by opening a “R and SparkR” notebook and entering the following statements.\n",
    "\n",
    "    a <- c('a','b','c')\n",
    "    a\n",
    "The result should be:\n",
    "\n",
    "![](jupyterR.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test SparkR\n",
    "To test SparkR, we will put some test data into your users HFDS home directory (/user/abr). We will parse CSV data and therefore must download and install a parser to be used from the notebook. Run the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remote sudo wget http://central.maven.org/maven2/com/databricks/spark-csv_2.11/1.5.0/spark-csv_2.11-1.5.0.jar -O /usr/iop/current/spark-client/lib/spark-csv_2.11-1.5.0.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some test data and upload it to the HDFS directory. Run the following commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remote << EOL\n",
    "wget -q https://github.com/databricks/spark-csv/raw/master/src/test/resources/cars.csv\n",
    "hdfs dfs -put cars.csv .\n",
    "EOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you can test R and SparkR by parsing the CSV file and loading the data in an R Data Frame. If the CSV data source is not already part of your Spark installation, you'll have to download it and add it to your Spark libraries.\n",
    "Now, run the Jupyter notebook server as yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new notebook using the “R and SparkR” kernel. Put the following code inside (mind the correct spark-csv version) and run it.\n",
    "\n",
    "    Sys.setenv(SPARK_HOME='/usr/iop/current/spark-client')\n",
    "    .libPaths(c(file.path(Sys.getenv('SPARK_HOME'), 'R', 'lib'), .libPaths()))\n",
    "    library(SparkR)\n",
    "    sc <- sparkR.init(master='yarn-client', sparkPackages=\"com.databricks:spark-csv_2.11:1.5.0\")\n",
    "    sqlContext <- sparkRSQL.init(sc)\n",
    "    df <- read.df(sqlContext, \"cars.csv\", source = \"com.databricks.spark.csv\", inferSchema = \"true\", header=\"true\")\n",
    "    head(df) \n",
    "    \n",
    "The result should be the following.\n",
    "![](jupyterSparkR.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the Spark-Scala kernel (through Apache Toree)\n",
    "The steps in this section are required to be able to run Spark Scala scripts from the Jupyter notebook. Run the following commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remotesudo pip install toree\n",
    "remotesudo jupyter toree install --spark_home=/usr/iop/4.2.0.0/spark/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the Scala Spark kernel to use yarn, by the SPARK_OPTS parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to kac-srv-001.kac.sblokalnet closed.\n",
      "Pseudo-terminal will not be allocated because stdin is not a terminal.\n",
      "\n",
      "{\n",
      "  \"argv\": [\n",
      "    \"/usr/local/share/jupyter/kernels/apache_toree_scala/bin/run.sh\",\n",
      "    \"--profile\",\n",
      "    \"{connection_file}\"\n",
      "  ],\n",
      "  \"display_name\": \"Scala and Spark\",\n",
      "  \"env\": {\n",
      "    \"DEFAULT_INTERPRETER\": \"Scala\",\n",
      "    \"PYTHON_EXEC\": \"python\",\n",
      "    \"SPARK_OPTS\": \"--master yarn-client\",\n",
      "    \"SPARK_HOME\": \"/usr/iop/4.2.0.0/spark/\",\n",
      "    \"TOREE_OPTS\": \"\",\n",
      "    \"PYTHONPATH\": \"/usr/iop/4.2.0.0/spark/python:/usr/iop/4.2.0.0/spark/python/lib/py4j-0.9-src.zip\"\n",
      "  },\n",
      "  \"language\": \"scala\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "remote sudo mkdir -p /usr/local/share/jupyter/kernels/apache_toree_scala\n",
    "python << EOJ | remotesudo tee  /usr/local/share/jupyter/kernels/apache_toree_scala/kernel.json\n",
    "print(\"\"\"\n",
    "{\n",
    "  \"argv\": [\n",
    "    \"/usr/local/share/jupyter/kernels/apache_toree_scala/bin/run.sh\",\n",
    "    \"--profile\",\n",
    "    \"{connection_file}\"\n",
    "  ],\n",
    "  \"display_name\": \"Scala and Spark\",\n",
    "  \"env\": {\n",
    "    \"DEFAULT_INTERPRETER\": \"Scala\",\n",
    "    \"PYTHON_EXEC\": \"python\",\n",
    "    \"SPARK_OPTS\": \"--master yarn-client\",\n",
    "    \"SPARK_HOME\": \"/usr/iop/4.2.0.0/spark/\",\n",
    "    \"TOREE_OPTS\": \"\",\n",
    "    \"PYTHONPATH\": \"/usr/iop/4.2.0.0/spark/python:/usr/iop/4.2.0.0/spark/python/lib/py4j-0.9-src.zip\"\n",
    "  },\n",
    "  \"language\": \"scala\"\n",
    "}\"\"\")\n",
    "EOJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Spark-Scala\n",
    "Now, run the Jupyter notebook server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new Apache Toree - Scala notebook and enter the following statements:\n",
    "\n",
    "    val NUM_SAMPLES=1000000\n",
    "    val count = sc.parallelize(1 to NUM_SAMPLES).map{i =>\n",
    "      val x = Math.random()\n",
    "      val y = Math.random()\n",
    "      if (x*x + y*y < 1) 1 else 0\n",
    "    }.reduce(_ + _)\n",
    "    println(\"Pi is roughly \" + 4.0 * count / NUM_SAMPLES)\n",
    "You should expect the following result.\n",
    "![](jupyterScala.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Installing JupyterHub\n",
    "When the Jupyter notebook is up and running and basic tests have been performed, it is now time to implement the multi-tenant access to Jupyter, through JupyterHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install NodeJS and its package manager\n",
    "JupyterHub is distributed as a NodeJS web application, so first NodeJS and its package manager must be installed. Execute the following commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remotesudo yum install -y npm nodejs\n",
    "remotesudo npm install -g configurable-http-proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install JupyterHub\n",
    "Install JupyterHub using pip (part of the Anaconda for Python3 installation). Run the following commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remotesudo pip install jupyterhub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure JupyterHub\n",
    "Once installed, create an initial configuration in the /etc/jupyter directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remotesudo jupyterhub -y True --generate-config --config=/etc/jupyterhub/jupyterhub_config.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test JupyterHub\n",
    "To check that JupyterHub works, we will first run it as user **root** without SSL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remotesudo jupyterhub -f /etc/jupyterhub/jupyterhub_config.py --no-ssl --ip=\\$\\(hostname -f \\)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the users connecting to JupyterHub will be validated by the operating system using PAM authentication. The users we connect with must have a password.\n",
    "\n",
    "For the validation we assume that two non-privileged users exist on the system, **nick** and **frank**. Both users have a home directory on the Linux file system and an HDFS directory they own, respectively /user/nick and /user/frank. The permissions on the HDFS directories have been set to 700 so that only the owner of the directory has full access rights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remote << EOL\n",
    "sudo hdfs dfs -mkdir /user/nick\n",
    "sudo hdfs dfs -mkdir /user/frank\n",
    "sudo hdfs dfs -chown nick:nick /user/nick\n",
    "sudo hdfs dfs -chown frank:frank /user/frank\n",
    "sudo hdfs dfs -chmod 700 /user/nick \n",
    "sudo hdfs dfs -chmod 700 /user/frank\n",
    "EOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, connect to JupyterHub through URL `http://<server-name>:8000`\n",
    "\n",
    "![](hubLogin.png)\n",
    "\n",
    "Log on with user **nick** and the specified password. The list of notebooks should be empty and the permissions are applied when connecting to the HDFS.\n",
    "\n",
    "Create a Scala notebook and enter the following statements.\n",
    "\n",
    "    import scala.io.Source\n",
    "    val html = scala.io.Source.fromURL(\"https://github.com/databricks/spark-csv/raw/master/src/test/resources/cars.csv\").mkString\n",
    "    val list = html.split(\"\\n\").filter(_ != \"\")\n",
    "    val rdds = sc.parallelize(list)\n",
    "    rdds.saveAsTextFile(\"/user/nick/cars.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now log on as user **frank**, create a new notebook and try to access the file in directory /user/nick.\n",
    "\n",
    "    val rdd=sc.textFile(\"/user/nick/car.csv\")\n",
    "    rdd.count    \n",
    "    \n",
    "You will get an error as user **frank** is not allowed to access the file in directory /user/nick.    \n",
    "\n",
    "![](permissionError.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locking down the environment\n",
    "Once you have installed JupyterHub and validated its working, it is best to put some security in place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running JupyterHub without root\n",
    "First steps taken from\n",
    "https://github.com/jupyterhub/jupyterhub/wiki/Using-sudo-to-run-JupyterHub-without-root-privileges "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we install the sudo spawner, that allows jupyterhub to spawn new jupyters as the logged in user via sudo. This is nessesary when jupyterhub is not running as root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/jupyter/sudospawner\n",
      "  Cloning https://github.com/jupyter/sudospawner to ./pip-ucixvgap-build\n",
      "Requirement already satisfied (use --upgrade to upgrade): jupyterhub>=0.4 in /opt/anaconda3/lib/python3.5/site-packages (from sudospawner==0.3.0)\n",
      "Requirement already satisfied (use --upgrade to upgrade): notebook in /opt/anaconda3/lib/python3.5/site-packages (from sudospawner==0.3.0)\n",
      "Requirement already satisfied (use --upgrade to upgrade): requests in /opt/anaconda3/lib/python3.5/site-packages (from jupyterhub>=0.4->sudospawner==0.3.0)\n",
      "Requirement already satisfied (use --upgrade to upgrade): tornado>=4.1 in /opt/anaconda3/lib/python3.5/site-packages (from jupyterhub>=0.4->sudospawner==0.3.0)\n",
      "Requirement already satisfied (use --upgrade to upgrade): traitlets>=4.1 in /opt/anaconda3/lib/python3.5/site-packages (from jupyterhub>=0.4->sudospawner==0.3.0)\n",
      "Requirement already satisfied (use --upgrade to upgrade): sqlalchemy>=1.0 in /opt/anaconda3/lib/python3.5/site-packages (from jupyterhub>=0.4->sudospawner==0.3.0)\n",
      "Requirement already satisfied (use --upgrade to upgrade): pamela in /opt/anaconda3/lib/python3.5/site-packages (from jupyterhub>=0.4->sudospawner==0.3.0)\n",
      "Requirement already satisfied (use --upgrade to upgrade): jinja2 in /opt/anaconda3/lib/python3.5/site-packages (from jupyterhub>=0.4->sudospawner==0.3.0)\n",
      "Requirement already satisfied (use --upgrade to upgrade): MarkupSafe in /opt/anaconda3/lib/python3.5/site-packages (from jinja2->jupyterhub>=0.4->sudospawner==0.3.0)\n",
      "Installing collected packages: sudospawner\n",
      "  Running setup.py install for sudospawner ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25hSuccessfully installed sudospawner-0.3.0\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Connection to kac-srv-001.kac.sblokalnet closed.\n"
     ]
    }
   ],
   "source": [
    "remotesudo pip install git+https://github.com/jupyter/sudospawner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it is not so easy. There are a number of further steps we need to go through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create a jupyterhub user - rhea\n",
    "\n",
    "From some defaults, we have chosen the user to be called rhea. Create this user in whatever fashion is appropriate for your system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Give rhea sudo access\n",
    "\n",
    "We need to enable the user (rhea) to run sudo\n",
    "\n",
    "Add/replace this into /etc/sudoers\n",
    "\n",
    "    Defaults    secure_path = /sbin:/bin:/usr/sbin:/usr/bin:/opt/anaconda3/bin\n",
    "    #Defaults    requiretty\n",
    "\n",
    "In effect, we add the anaconda bin dir to the path that will always be available for sudo commands. This is nessesary. And we drop the requirement that you must have a tty. This is nessesary. It would be nicer if this could be done from FreeIPA, but....\n",
    "\n",
    "This could probably be setup for specific users instead of a global setting...\n",
    "\n",
    "Oh, and rhea must have passwordless sudo. Possible it is enough to give her access to sudospawner, but this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Defaults entries for rhea on this host:\n",
      "    !visiblepw, always_set_home, env_reset, env_keep=\"COLORS DISPLAY HOSTNAME\n",
      "    HISTSIZE INPUTRC KDEDIR LS_COLORS\", env_keep+=\"MAIL PS1 PS2 QTDIR USERNAME\n",
      "    LANG LC_ADDRESS LC_CTYPE\", env_keep+=\"LC_COLLATE LC_IDENTIFICATION\n",
      "    LC_MEASUREMENT LC_MESSAGES\", env_keep+=\"LC_MONETARY LC_NAME LC_NUMERIC\n",
      "    LC_PAPER LC_TELEPHONE\", env_keep+=\"LC_TIME LC_ALL LANGUAGE LINGUAS\n",
      "    _XKB_CHARSET XAUTHORITY\",\n",
      "    secure_path=/sbin\\:/bin\\:/usr/sbin\\:/usr/bin\\:/opt/anaconda3/bin\n",
      "\n",
      "User rhea may run the following commands on this host:\n",
      "    (ALL : ALL) NOPASSWD: /opt/anaconda3/bin/sudospawner\n",
      "Connection to kac-srv-001.kac.sblokalnet closed.\n"
     ]
    }
   ],
   "source": [
    "remote sudo -U rhea -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should give something like\n",
    "\n",
    "    Matching Defaults entries for rhea on this host:\n",
    "        !visiblepw, always_set_home, env_reset, env_keep=\"COLORS DISPLAY HOSTNAME HISTSIZE INPUTRC KDEDIR LS_COLORS\", env_keep+=\"MAIL PS1 PS2 QTDIR USERNAME LANG LC_ADDRESS LC_CTYPE\", env_keep+=\"LC_COLLATE\n",
    "        LC_IDENTIFICATION LC_MEASUREMENT LC_MESSAGES\", env_keep+=\"LC_MONETARY LC_NAME LC_NUMERIC LC_PAPER LC_TELEPHONE\", env_keep+=\"LC_TIME LC_ALL LANGUAGE LINGUAS _XKB_CHARSET XAUTHORITY\",\n",
    "        secure_path=/sbin\\:/bin\\:/usr/sbin\\:/usr/bin\\:/opt/anaconda3/bin\n",
    "\n",
    "    User rhea may run the following commands on this host:\n",
    "        (%biusers : ALL) NOPASSWD: /opt/anaconda3/bin/sudospawner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DBUS\n",
    "\n",
    "If you get errors like this in /var/log/messages\n",
    "\n",
    "    [system] Rejected send message, 2 matched rules; type=\"method_call\", sender=\":1.2292\" (uid=1031 pid=59107 comm=\"/opt/anaconda3/bin/python /opt/anaconda3/bin/jupyt\") interface=\"org.freedesktop.login1.Manager\" member=\"CreateSession\" error name=\"(unset)\" requested_reply=\"0\" destination=\"org.freedesktop.login1\" (uid=0 pid=823 comm=\"/usr/lib/systemd/systemd-logind \")\n",
    "\n",
    "You need to enable the user rhea to handle login sessions. Per default, only processes run as root can do logins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "python << EOX | remotesudo tee  /etc/dbus-1/system.d/jupyterhub.conf\n",
    "print(\"\"\"\n",
    "<?xml version=\"1.0\"?> <!--*-nxml-*-->\n",
    "<!DOCTYPE busconfig PUBLIC \"-//freedesktop//DTD D-BUS Bus Configuration 1.0//EN\"\n",
    "        \"http://www.freedesktop.org/standards/dbus/1.0/busconfig.dtd\">\n",
    "<busconfig>\n",
    "        <policy user=\"rhea\">\n",
    "                <allow send_destination=\"org.freedesktop.login1\"/>\n",
    "                <allow receive_sender=\"org.freedesktop.login1\"/>\n",
    "        </policy>\n",
    "</busconfig>\n",
    "\"\"\")\n",
    "EOX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart the dbus deamon. This disconnects the login daemon.... So restart it also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remotesudo service dbus restart\n",
    "remotesudo systemctl restart systemd-logind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PAM\n",
    "\n",
    "JupyterHub authenticates as the \"login\" pam service. I feel that it is a lot more clear to make a separate pam service for jupyterhub. To do this, we duplicate the login service as a new pam service \"jupyterhub\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remotesudo cp /etc/pam.d/login /etc/pam.d/jupyterhub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then /etc/jupyterhub/jupyterhub_config.py in uncomment this line\n",
    "\n",
    "    c.PAMAuthenticator.service = 'jupyterhub'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up SSL encryption\n",
    "Refer to section https://github.com/jupyterhub/jupyterhub/blob/master/docs/source/getting-started.md#ssl-encryption for setting up SSL for JupyterHub. After setting up SSL, remotesudo sed -i \\\"sI.*c\\.JupyterHub\\.ssl_cert.*Ic.JupyterHub.ssl_cert = '/etc/ssl/certs/juputerhub.crt'Ig\\\" /etc/jupyterhub/jupyterhub_config.py\n",
    "you should run JupyterHub without the --no-ssl parameter.\n",
    "\n",
    "\n",
    "##### Generate a SSL certificate\n",
    "Skip this step if you already have a ssl certificate you want to use\n",
    "\n",
    "Generate the request\n",
    "\n",
    "    openssl req -new > jupyterhub.ssl.csr\n",
    "\n",
    "Generate the certificate\n",
    "\n",
    "\topenssl rsa -in privkey.pem -out jupyterhub.cert.key\n",
    "\topenssl x509 -in jupyterhub.ssl.csr -out jupyterhub.cert.cert -req -signkey jupyterhub.cert.key\n",
    "\n",
    "These steps require you to enter a password, so do them locally, not through this workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Install the SSL certificate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with sudo and kerberos-enabled automounted home folders in my system, so I created this function to allow me to use sudo to cp a file from my home folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo-terminal will not be allocated because stdin is not a terminal.\n",
      "\n",
      "function root_cp(){\n",
      "        files=\"\"\n",
      "        name=\"\"\n",
      "        if [ -d \"\" ]; then\n",
      "                for file in ; do\n",
      "                        cat \"\" | sudo bash -c \"cat - > \"/$(basename )\"\"\n",
      "                done\n",
      "        else\n",
      "                for file in ; do\n",
      "                        cat \"\" | sudo bash -c \"cat - > \"\"\"\n",
      "                done\n",
      "        fi\n",
      "}\n",
      "export root_cp \n",
      "\n"
     ]
    }
   ],
   "source": [
    "python << EOB | remotesudo tee  /etc/profile.d/root_cp.sh\n",
    "print(\"\"\"\n",
    "function root_cp(){\n",
    "        files=\"${@:1:$(($#-1))}\"\n",
    "        name=\"${@: -1}\"\n",
    "        if [ -d \"$name\" ]; then\n",
    "                for file in $files; do\n",
    "                        cat \"$file\" | sudo bash -c \"cat - > \\\"$name/\\$(basename $file)\\\"\"\n",
    "                done\n",
    "        else\n",
    "                for file in $files; do\n",
    "                        cat \"$file\" | sudo bash -c \"cat - > \\\"$name\\\"\"\n",
    "                done\n",
    "        fi\n",
    "}\n",
    "export root_cp \n",
    "\"\"\")\n",
    "EOB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the certificate in the expected location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to kac-srv-001.kac.sblokalnet closed.\n",
      "Connection to kac-srv-001.kac.sblokalnet closed.\n",
      "Connection to kac-srv-001.kac.sblokalnet closed.\n",
      "Connection to kac-srv-001.kac.sblokalnet closed.\n",
      "Connection to kac-srv-001.kac.sblokalnet closed.\n"
     ]
    }
   ],
   "source": [
    "remote root_cp jupyterhub.cert.cert /etc/ssl/certs/juputerhub.crt\n",
    "remotesudo mkdir -p /etc/ssl/private\n",
    "remote root_cp ~/jupyterhub.cert.key /etc/ssl/private/jupyterhub.key\n",
    "remotesudo chown rhea /etc/ssl/private/jupyterhub.key\n",
    "remotesudo chmod o-rwx /etc/ssl/private/jupyterhub.key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure Jupyterhub to use this certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to kac-srv-001.kac.sblokalnet closed.\n",
      "Connection to kac-srv-001.kac.sblokalnet closed.\n",
      "#c.JupyterHub.confirm_no_\u001b[01;31m\u001b[Kssl\u001b[m\u001b[K = False\n",
      "#  Use with \u001b[01;31m\u001b[Kssl\u001b[m\u001b[K_key\n",
      "c.JupyterHub.\u001b[01;31m\u001b[Kssl\u001b[m\u001b[K_cert = '/etc/\u001b[01;31m\u001b[Kssl\u001b[m\u001b[K/certs/jupyterhub.crt'\n",
      "#  Use with \u001b[01;31m\u001b[Kssl\u001b[m\u001b[K_cert\n",
      "c.JupyterHub.\u001b[01;31m\u001b[Kssl\u001b[m\u001b[K_key = '/etc/\u001b[01;31m\u001b[Kssl\u001b[m\u001b[K/private/jupyterhub.key'\n",
      "Connection to kac-srv-001.kac.sblokalnet closed.\n"
     ]
    }
   ],
   "source": [
    "key1=\"c\\.JupyterHub\\.ssl_cert\"\n",
    "value1=\"c.JupyterHub.ssl_cert = '/etc/ssl/certs/jupyterhub.crt'\"\n",
    "remotesudo sed -i \\\"sI.*${key1}.*I${value1}Ig\\\" /etc/jupyterhub/jupyterhub_config.py\n",
    "\n",
    "key2=\"c\\.JupyterHub\\.ssl_key\"\n",
    "value2=\"c.JupyterHub.ssl_key = '/etc/ssl/private/jupyterhub.key'\"\n",
    "remotesudo sed -i \\\"sI.*${key2}.*I${value2}Ig\\\" /etc/jupyterhub/jupyterhub_config.py\n",
    "\n",
    "remote grep ssl /etc/jupyterhub/jupyterhub_config.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a whitelist of allowed users\n",
    "This is an extra security measure so that only a specific group of users can access JupyterHub. Update the /etc/jupyter/jupyterhub_config.py file and update the c.Authenticator.whitelist parameter to only include those users who can have access.\n",
    "More information can be found here: https://github.com/jupyterhub/jupyterhub/blob/master/docs/source/getting-started.md#authentication-and-users "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create directories to keep the notebooks\n",
    "To keep notebooks secured from access by other users, it is best to create a directory under the user's home directory and specify this directory as the default notebook directory. More information can be found here: https://github.com/jupyterhub/jupyterhub/blob/master/docs/source/getting-started.md#spawners-and-single-user-notebook-servers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JupyterHub as system service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo-terminal will not be allocated because stdin is not a terminal.\n",
      "\n",
      "[Unit]\n",
      "Description=Jupyterhub\n",
      "After=network-online.target\n",
      "\n",
      "[Service]\n",
      "#The system user for jupyterhub\n",
      "User=rhea\n",
      "\n",
      "#Two ways of specifying the runtime directory\n",
      "RuntimeDirectory=jupyterhub\n",
      "WorkingDirectory=/var/run/jupyterhub\n",
      "\n",
      "#This sets up the logging directory\n",
      "PermissionsStartOnly=true\n",
      "ExecStartPre=/usr/bin/mkdir -p /var/log/jupyterhub\n",
      "ExecStartPre=/usr/bin/touch /var/log/jupyterhub/jupyterhub.log\n",
      "ExecStartPre=/usr/bin/chown rhea /var/log/jupyterhub -R\n",
      "\n",
      "#Set the path to include anaconda3\n",
      "Environment=\"PATH=/opt/anaconda3/bin/:/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin\"\n",
      "\n",
      "#Param explanation\n",
      "#Config = path to config file\n",
      "#Log file = the log file we did all the work above to get writable\n",
      "#ip = the ip where the server will listen. Set to $SERVER, defined in this workbook\n",
      "#spawner = use the sudo spawner\n",
      "ExecStart=/opt/anaconda3/bin/jupyterhub --config=/etc/jupyterhub/jupyterhub_config.py --log-file=/var/log/jupyterhub/jupyterhub.log --ip=\"kac-srv-001.kac.sblokalnet\" --JupyterHub.spawner_class=sudospawner.SudoSpawner\n",
      "#--no-ssl \n",
      "[Install]\n",
      "WantedBy=multi-user.target\n",
      "\n",
      "Connection to kac-srv-001.kac.sblokalnet closed.\n"
     ]
    }
   ],
   "source": [
    "python << EOS | remotesudo tee  /lib/systemd/system/jupyterhub.service\n",
    "print(\"\"\"\n",
    "[Unit]\n",
    "Description=Jupyterhub\n",
    "After=network-online.target\n",
    "\n",
    "[Service]\n",
    "#The system user for jupyterhub\n",
    "User=rhea\n",
    "\n",
    "#Two ways of specifying the runtime directory\n",
    "RuntimeDirectory=jupyterhub\n",
    "WorkingDirectory=/var/run/jupyterhub\n",
    "\n",
    "#This sets up the logging directory\n",
    "PermissionsStartOnly=true\n",
    "ExecStartPre=/usr/bin/mkdir -p /var/log/jupyterhub\n",
    "ExecStartPre=/usr/bin/touch /var/log/jupyterhub/jupyterhub.log\n",
    "ExecStartPre=/usr/bin/chown rhea /var/log/jupyterhub -R\n",
    "\n",
    "#Set the path to include anaconda3\n",
    "Environment=\"PATH=/opt/anaconda3/bin/:/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin\"\n",
    "\n",
    "#Param explanation\n",
    "#Config = path to config file\n",
    "#Log file = the log file we did all the work above to get writable\n",
    "#ip = the ip where the server will listen. Set to \\$SERVER, defined in this workbook\n",
    "#spawner = use the sudo spawner\n",
    "ExecStart=/opt/anaconda3/bin/jupyterhub \\\n",
    "--config=/etc/jupyterhub/jupyterhub_config.py \\\n",
    "--log-file=/var/log/jupyterhub/jupyterhub.log \\\n",
    "--ip=\"$SERVER\" \\\n",
    "--JupyterHub.spawner_class=sudospawner.SudoSpawner \\\n",
    "--no-ssl\n",
    "\n",
    "[Install]\n",
    "WantedBy=multi-user.target\n",
    "\"\"\")\n",
    "EOS\n",
    "remotesudo systemctl daemon-reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to kac-srv-001.kac.sblokalnet closed.\n",
      "Connection to kac-srv-001.kac.sblokalnet closed.\n",
      "\u001b[1;32m●\u001b[0m jupyterhub.service - Jupyterhub\n",
      "   Loaded: loaded (/usr/lib/systemd/system/jupyterhub.service; enabled; vendor preset: disabled)\n",
      "   Active: \u001b[1;32mactive (running)\u001b[0m since tor 2016-11-17 16:59:36 CET; 330ms ago\n",
      "  Process: 17740 ExecStartPre=/usr/bin/chown rhea /var/log/jupyterhub -R (code=exited, status=0/SUCCESS)\n",
      "  Process: 17738 ExecStartPre=/usr/bin/touch /var/log/jupyterhub/jupyterhub.log (code=exited, status=0/SUCCESS)\n",
      "  Process: 17735 ExecStartPre=/usr/bin/mkdir -p /var/log/jupyterhub (code=exited, status=0/SUCCESS)\n",
      " Main PID: 17742 (jupyterhub)\n",
      "   CGroup: /system.slice/jupyterhub.service\n",
      "           └─17742 /opt/anaconda3/bin/python /opt/anaconda3/bin/jupyterhub --config=/etc/jupyterhub/jupyterhub_config.py --log-file=/var/log/jupyterhub/jupyterhub.log --ip=\"kac-srv-001.kac.sblokalnet\" --JupyterHub.spawner_class=sudospawner.SudoSpawner\n",
      "\n",
      "nov 17 16:59:36 kac-srv-001.kac.sblokalnet systemd[1]: Starting Jupyterhub...\n",
      "nov 17 16:59:36 kac-srv-001.kac.sblokalnet systemd[1]: Started Jupyterhub.\n",
      "Connection to kac-srv-001.kac.sblokalnet closed.\n"
     ]
    }
   ],
   "source": [
    "remotesudo systemctl stop jupyterhub\n",
    "remotesudo systemctl start jupyterhub\n",
    "remotesudo systemctl status jupyterhub -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m●\u001b[0m jupyterhub.service - Jupyterhub\n",
      "   Loaded: loaded (/usr/lib/systemd/system/jupyterhub.service; enabled; vendor preset: disabled)\n",
      "   Active: \u001b[1;32mactive (running)\u001b[0m since tor 2016-11-17 16:59:36 CET; 17h ago\n",
      "  Process: 17740 ExecStartPre=/usr/bin/chown rhea /var/log/jupyterhub -R (code=exited, status=0/SUCCESS)\n",
      "  Process: 17738 ExecStartPre=/usr/bin/touch /var/log/jupyterhub/jupyterhub.log (code=exited, status=0/SUCCESS)\n",
      "  Process: 17735 ExecStartPre=/usr/bin/mkdir -p /var/log/jupyterhub (code=exited, status=0/SUCCESS)\n",
      " Main PID: 17742 (jupyterhub)\n",
      "   CGroup: /system.slice/jupyterhub.service\n",
      "           ├─17742 /opt/anaconda3/bin/python /opt/anaconda3/bin/jupyterhub --config=/etc/jupyterhub/jupyterhub_config.py --log-file=/var/log/jupyterhub/jupyterhub.log --ip=\"kac-srv-001.kac.sblokalnet\" --JupyterHub.spawner_class=sudospawner.SudoSpawner\n",
      "           └─17769 node /bin/configurable-http-proxy --ip kac-srv-001.kac.sblokalnet --port 8000 --api-ip 127.0.0.1 --api-port 8001 --default-target http://127.0.0.1:8081 --error-target http://127.0.0.1:8081/hub/error --ssl-key /etc/ssl/private/jupyterhub.key --ssl-cert /etc/ssl/certs/jupyterhub.crt\n",
      "\n",
      "nov 17 16:59:37 kac-srv-001.kac.sblokalnet jupyterhub[17742]: [I 2016-11-17 16:59:37.035 JupyterHub app:643] Writing cookie_secret to /run/jupyterhub/jupyterhub_cookie_secret\n",
      "nov 17 16:59:37 kac-srv-001.kac.sblokalnet jupyterhub[17742]: [W 2016-11-17 16:59:37.082 JupyterHub app:304]\n",
      "nov 17 16:59:37 kac-srv-001.kac.sblokalnet jupyterhub[17742]: Generating CONFIGPROXY_AUTH_TOKEN. Restarting the Hub will require restarting the proxy.\n",
      "nov 17 16:59:37 kac-srv-001.kac.sblokalnet jupyterhub[17742]: Set CONFIGPROXY_AUTH_TOKEN env or JupyterHub.proxy_auth_token config to avoid this message.\n",
      "nov 17 16:59:37 kac-srv-001.kac.sblokalnet jupyterhub[17742]: [I 2016-11-17 16:59:37.094 JupyterHub app:785] Not using whitelist. Any authenticated user will be allowed.\n",
      "nov 17 16:59:37 kac-srv-001.kac.sblokalnet jupyterhub[17742]: [I 2016-11-17 16:59:37.133 JupyterHub app:1231] Hub API listening on http://127.0.0.1:8081/hub/\n",
      "nov 17 16:59:37 kac-srv-001.kac.sblokalnet jupyterhub[17742]: [I 2016-11-17 16:59:37.137 JupyterHub app:968] Starting proxy @ http://kac-srv-001.kac.sblokalnet:8000/\n",
      "nov 17 16:59:37 kac-srv-001.kac.sblokalnet jupyterhub[17742]: 16:59:37.328 - info: [ConfigProxy] Proxying https://kac-srv-001.kac.sblokalnet:8000 to http://127.0.0.1:8081\n",
      "nov 17 16:59:37 kac-srv-001.kac.sblokalnet jupyterhub[17742]: 16:59:37.333 - info: [ConfigProxy] Proxy API at http://127.0.0.1:8001/api/routes\n",
      "nov 17 16:59:37 kac-srv-001.kac.sblokalnet jupyterhub[17742]: [I 2016-11-17 16:59:37.343 JupyterHub app:1254] JupyterHub is now running at http://kac-srv-001.kac.sblokalnet:8000/\n",
      "\u001b[1;31mWarning:\u001b[0m jupyterhub.service changed on disk. Run 'systemctl daemon-reload' to reload units.\n",
      "Connection to kac-srv-001.kac.sblokalnet closed.\n"
     ]
    }
   ],
   "source": [
    "remotesudo systemctl status jupyterhub -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to kac-srv-001.kac.sblokalnet closed.\r\n"
     ]
    }
   ],
   "source": [
    "remotesudo systemctl stop jupyterhub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make jupyterhub admin users\n",
    "\n",
    "Made abr-sadm an initial admin user for jupyterhub\n",
    "\n",
    "in /etc/jupyterhub/jupyterhub_config.py, uncomment/add this line or use the code below\n",
    "\n",
    "    c.Authenticator.admin_users = {'abr-sadm'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to kac-srv-001.kac.sblokalnet closed.\n",
      "## DEPRECATED, use Authenticator.\u001b[01;31m\u001b[Kadmin_users\u001b[m\u001b[K instead.\n",
      "#c.JupyterHub.\u001b[01;31m\u001b[Kadmin_users\u001b[m\u001b[K = set()\n",
      "c.Authenticator.\u001b[01;31m\u001b[Kadmin_users\u001b[m\u001b[K = {'abr-sadm'}\n",
      "Connection to kac-srv-001.kac.sblokalnet closed.\n"
     ]
    }
   ],
   "source": [
    "key=\"c\\.Authenticator\\.admin_users\"\n",
    "newValue=\"c.Authenticator.admin_users = {'abr-sadm'}\"\n",
    "remotesudo sed -i \\\"sI.*${key}.*I${newValue}Ig\\\" /etc/jupyterhub/jupyterhub_config.py\n",
    "remote grep admin_users /etc/jupyterhub/jupyterhub_config.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart the jupyterhub service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redirecting to /bin/systemctl restart  jupyterhub.service\n",
      "Connection to kac-srv-001.kac.sblokalnet closed.\n"
     ]
    }
   ],
   "source": [
    "remotesudo service jupyterhub restart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made all the subadmin users jupyterhub admins via the web interface\n",
    "http://kac-srv-001.kac.sblokalnet:8000/hub/admin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "toc": {
   "nav_menu": {
    "height": "387px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "1004px",
    "left": "0px",
    "right": "1421px",
    "top": "106px",
    "width": "434px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
